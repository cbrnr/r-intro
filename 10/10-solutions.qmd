---
title: "10 – Lösungen"
subtitle: "Statistische Datenanalyse mit R"
author: "Clemens Brunner"
date: 2024-06-03
format:
  html:
    page-layout: full
engine: knitr
knitr:
  opts_chunk: 
    R.options:
      width: 120
highlight-style: github
title-block-banner: true
theme:
  light: flatly
  dark: darkly
lang: de
author-title: "Autor"
published-title: "Veröffentlicht"
---

## Übung 1

```{r}
#| message: false
library(ggplot2)
library(readr)

(cars = read_csv("cars.csv"))

plot(
    x=cars$speed,
    y=cars$dist,
    pch=21,
    bg=rgb(0, 0, 0, 0.5),
    xlab="Speed (miles per hour)",
    ylab="Distance (feet)"
)
abline(lm(dist ~ speed, data=cars), col="blue", lwd=2)
```


## Übung 2

```{r}
model = lm(dist ~ speed, data=cars)
summary(model)
```


## Übung 3

```{r}
r = with(cars, cor(speed, dist))
r**2  # identical to R² from linear regression
summary(model)$r.squared
```


## Übung 4

Die Geradengleichung lautet:

$$y = b_0 + b_1 \cdot x$$

Eingesetzt mit den Werten der Koeffizienten:

$$y = -17.5791 + 3.9324 \cdot x$$

Und die Vorhersagen:

$$-17.5791 + 3.9324 \cdot 5 = 2.08$$
$$-17.5791 + 3.9324 \cdot 65 = 238.03$$

```{r}
predict(model, data.frame(speed=c(5, 65)))
```


## Übung 5

```{r}
#| message: false
library(tibble)

sales = read_tsv("sales2.dat")
sales = as_tibble(scale(sales))
model = lm(sales ~ adverts + airplay + attract, data=sales)
summary(model)
coef(model)  # stimmt mit lm.beta überein
```


## Übung 6

```{r}
#| message: false
library(lm.beta)  # für lm.beta

aggression = read_tsv("aggression.dat")

model1 = lm(Aggression ~ Parenting_Style + Sibling_Aggression, data=aggression)
summary(model1)  # beide Variablen erwartungsgemäß signifikant
lm.beta(model1)  # Parenting_Style hat größeren Einfluss als Sibling_Aggression

model2 = lm(
    Aggression ~ Parenting_Style + Sibling_Aggression + Television +
                 Computer_Games + Diet,
    data=aggression
)
summary(model2)
lm.beta(model2)

anova(model1, model2)  # Vergleich beider Modelle
```


## Übung 7

```{r}
library(car)  # für dwt, vif

# Kollinearität
vif(model2)

# Unabhängigkeit der Residuen
dwt(model2)

# Normalverteilung Residuen
plot(model2, which=2)

# Linearität und Varianzhomogenität
plot(model2, which=1)

# Punkte mit großem Einfluss
plot(model2, which=5)
```
